{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_cell_1",
   "metadata": {},
   "source": [
    "### Step 1: Environment Setup & Imports\n",
    "\n",
    "This cell installs necessary libraries including Transformers and Scikit-Learn, imports required modules for data processing and modeling, and sets random seeds to ensure reproducibility of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd24fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq protobuf==3.20.3\n",
    "!pip install -Uq transformers==4.48.0 accelerate==0.27.0 peft==0.8.2 sentencepiece emoji datasets scikit-learn seaborn\n",
    "\n",
    "import os\n",
    "import re\n",
    "import html\n",
    "import json\n",
    "import emoji\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    precision_recall_fscore_support, \n",
    "    confusion_matrix, \n",
    "    classification_report,\n",
    "    matthews_corrcoef\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer, \n",
    "    TrainingArguments,\n",
    "    DataCollatorWithPadding,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset\n",
    "\n",
    "SAMPLE_SIZE = 1000000\n",
    "MODEL_CHECKPOINT = \"microsoft/deberta-v3-base\" \n",
    "RANDOM_SEED = 42\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "print(\"‚úÖ System Initialized. Ready for 1M Run.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_2",
   "metadata": {},
   "source": [
    "### Step 2: Data Loading & Sampling\n",
    "\n",
    "This cell loads the Sentiment140 dataset, performs stratified sampling to create a balanced dataset of 1 million samples (500k positive, 500k negative), maps sentiment labels to binary values, and optimizes memory usage by deleting unused dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b9aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\">> Loading Data (Target: {SAMPLE_SIZE:,} rows)...\")\n",
    "\n",
    "INPUT_FILE = \"\"\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        if 'training' in filename and 'csv' in filename:\n",
    "            INPUT_FILE = os.path.join(dirname, filename)\n",
    "            break\n",
    "\n",
    "if not INPUT_FILE:\n",
    "    raise FileNotFoundError(\"‚ùå ERROR: Add 'sentiment140' dataset to Kaggle!\")\n",
    "\n",
    "try:\n",
    "    df_full = pd.read_csv(\n",
    "        INPUT_FILE, \n",
    "        encoding='latin-1', \n",
    "        header=None, \n",
    "        names=['sentiment', 'id', 'date', 'flag', 'user', 'text']\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "neg_df = df_full[df_full['sentiment'] == 0]\n",
    "pos_df = df_full[df_full['sentiment'] == 4]\n",
    "\n",
    "half_sample = SAMPLE_SIZE // 2\n",
    "neg_sample = neg_df.sample(n=half_sample, random_state=RANDOM_SEED)\n",
    "pos_sample = pos_df.sample(n=half_sample, random_state=RANDOM_SEED)\n",
    "\n",
    "df = pd.concat([neg_sample, pos_sample])\n",
    "df = df.sample(frac=1, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "\n",
    "df['sentiment'] = df['sentiment'].map({0: 0, 4: 1})\n",
    "\n",
    "del df_full, neg_df, pos_df, neg_sample, pos_sample\n",
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "print(f\"‚úÖ Data Loaded. Shape: {df.shape}\")\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_3",
   "metadata": {},
   "source": [
    "### Step 3: Data Preprocessing & Splitting\n",
    "\n",
    "This cell defines a text cleaning function to remove HTML tags, URLs, and user mentions while preserving emojis. It then applies this cleaning to the dataset and splits it into training, validation, and a held-out test set for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed415949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Applying Advanced Sanitization (Demojization + Cleaning)...\")\n",
    "\n",
    "URL_PATTERN = re.compile(r'http\\S+|www\\S+|https\\S+')\n",
    "USER_PATTERN = re.compile(r'@\\w+')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "    text = html.unescape(text)\n",
    "    text = emoji.demojize(text)\n",
    "    text = URL_PATTERN.sub('', text)\n",
    "    text = USER_PATTERN.sub('', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "\n",
    "test_size = 10000\n",
    "test_df = df.tail(test_size).copy()\n",
    "train_val_df = df.iloc[:-test_size]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train_val_df['text'], \n",
    "    train_val_df['sentiment'], \n",
    "    test_size=0.05, \n",
    "    stratify=train_val_df['sentiment'], \n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Preprocessing Done.\")\n",
    "print(f\"   Train Corpus: {len(X_train):,}\")\n",
    "print(f\"   Val Corpus:   {len(X_val):,}\")\n",
    "print(f\"   Test Corpus:  {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_4",
   "metadata": {},
   "source": [
    "### Step 4: Baseline Model Training\n",
    "\n",
    "This cell establishes a baseline performance metric using a TF-IDF vectorizer and a Logistic Regression classifier. This provides a benchmark to compare against the deep learning model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a45d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Training TF-IDF + Logistic Regression Baseline (1M Rows)...\")\n",
    "\n",
    "baseline_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(max_features=25000, ngram_range=(1,2)),\n",
    "    LogisticRegression(max_iter=1000, solver='liblinear')\n",
    ")\n",
    "\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "base_preds = baseline_pipeline.predict(test_df['text'])\n",
    "\n",
    "base_acc = accuracy_score(test_df['sentiment'], base_preds)\n",
    "base_mcc = matthews_corrcoef(test_df['sentiment'], base_preds)\n",
    "\n",
    "print(f\"\\n BASELINE RESULTS:\")\n",
    "print(f\"   Accuracy: {base_acc:.4f}\")\n",
    "print(f\"   MCC:      {base_mcc:.4f}\")\n",
    "print(\">> Note: DeBERTa is expected to significantly outperform this.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_5",
   "metadata": {},
   "source": [
    "### Step 5: Tokenization\n",
    "\n",
    "This cell initializes the DeBERTa V3 tokenizer and processes the text data by truncating sequences to a maximum length. It then converts the pandas DataFrames into Hugging Face Datasets and prepares a data collator for efficient batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\">> Loading Tokenizer: {MODEL_CHECKPOINT}...\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT, use_fast=False)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], truncation=True, max_length=128)\n",
    "\n",
    "train_dset = Dataset.from_dict({'text': X_train, 'label': y_train})\n",
    "val_dset = Dataset.from_dict({'text': X_val, 'label': y_val})\n",
    "test_dset_hf = Dataset.from_dict({'text': test_df['text'], 'label': test_df['sentiment']})\n",
    "\n",
    "print(\">> Tokenizing 1M rows (This may take 2-3 mins)...\")\n",
    "train_tokenized = train_dset.map(tokenize_function, batched=True)\n",
    "val_tokenized = val_dset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dset_hf.map(tokenize_function, batched=True)\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "print(\"‚úÖ Data ready for Tensor Cores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_6",
   "metadata": {},
   "source": [
    "### Step 6: Model Configuration\n",
    "\n",
    "This cell loads the pre-trained DeBERTa V3 model for sequence classification. It configures the training parameters, including batch size, learning rate, and evaluation strategy, and initializes the Trainer object to manage the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263aa6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='/kaggle/working/results',\n",
    "    \n",
    "    num_train_epochs=2,              \n",
    "    per_device_train_batch_size=32,  \n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=64,\n",
    "    \n",
    "    learning_rate=2e-5,              \n",
    "    weight_decay=0.01,\n",
    "    label_smoothing_factor=0.1,\n",
    "    lr_scheduler_type=\"cosine\",      \n",
    "    warmup_ratio=0.1,\n",
    "    \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=3000,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=3000,\n",
    "    save_total_limit=1,              \n",
    "    \n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    \n",
    "    fp16=True,\n",
    "    report_to=\"none\",\n",
    "    seed=RANDOM_SEED\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "print(\"‚úÖ Trainer Configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_7",
   "metadata": {},
   "source": [
    "### Step 7: Model Training\n",
    "\n",
    "This cell initiates the model training process using the configured Trainer. After training completes, it saves the fine-tuned model and tokenizer to the specified directory for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87cdfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\" STARTING 1 MILLION ROW TRAINING LOOP...\")\n",
    "print(\">> WARNING: This will take ~4 hours. Keep the tab active!\")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "save_path = \"/kaggle/working/saved_model\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "print(f\" Enterprise Model Saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_8",
   "metadata": {},
   "source": [
    "### Step 8: Model Evaluation\n",
    "\n",
    "This cell generates predictions on the held-out test set using the fine-tuned model. It calculates key performance metrics such as Accuracy, F1 Score, Precision, Recall, and Matthews Correlation Coefficient (MCC) to evaluate the model's effectiveness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47e93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\">> Running Inference on Held-out Test Set...\")\n",
    "preds_logits = trainer.predict(test_tokenized)\n",
    "preds = np.argmax(preds_logits.predictions, axis=-1)\n",
    "\n",
    "acc = accuracy_score(test_df['sentiment'], preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(test_df['sentiment'], preds, average='binary')\n",
    "mcc = matthews_corrcoef(test_df['sentiment'], preds)\n",
    "\n",
    "print(f\"\\nüèÜ FINAL RESULTS (1 MILLION DATASET)\")\n",
    "print(f\"{'='*30}\")\n",
    "print(f\"Baseline MCC:      {base_mcc:.4f}\")\n",
    "print(f\"DeBERTa V3 MCC:    {mcc:.4f}  (Improvement: +{mcc-base_mcc:.4f})\")\n",
    "print(f\"{'-'*30}\")\n",
    "print(f\"Accuracy:          {acc:.4f}\")\n",
    "print(f\"F1 Score:          {f1:.4f}\")\n",
    "print(f\"Precision:         {precision:.4f}\")\n",
    "print(f\"Recall:            {recall:.4f}\")\n",
    "print(f\"{'='*30}\")\n",
    "\n",
    "metrics = {\"accuracy\": acc, \"f1\": f1, \"mcc\": mcc, \"baseline_mcc\": base_mcc}\n",
    "with open(\"final_metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_cell_9",
   "metadata": {},
   "source": [
    "### Step 9: Visualization & Error Analysis\n",
    "\n",
    "This cell visualizes the model's performance using a confusion matrix heatmap. It also performs a qualitative error analysis by displaying examples of false positives and false negatives to understand where the model misclassified samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919073c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_df['sentiment'], preds)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Purples', \n",
    "            xticklabels=['Negative', 'Positive'], \n",
    "            yticklabels=['Negative', 'Positive'])\n",
    "plt.title('DeBERTa V3 (1M) Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.savefig('confusion_matrix.png')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüîç QUALITATIVE ERROR ANALYSIS\")\n",
    "test_df['pred'] = preds\n",
    "errors = test_df[test_df['sentiment'] != test_df['pred']]\n",
    "\n",
    "print(f\"Total Errors: {len(errors)}\")\n",
    "print(\"\\n[False Positives] Predicted Positive, Actually Negative:\")\n",
    "for txt in errors[errors['pred'] == 1]['text'].head(3):\n",
    "    print(f\" üî¥ {txt}\")\n",
    "\n",
    "print(\"\\n[False Negatives] Predicted Negative, Actually Positive:\")\n",
    "for txt in errors[errors['pred'] == 0]['text'].head(3):\n",
    "    print(f\" üîµ {txt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1379943",
   "metadata": {},
   "source": [
    "### Step 10: Deployment Dashboard\n",
    "\n",
    "To run the interactive dashboard, execute the following command in your terminal:\n",
    "`python app.py`\n",
    "\n",
    "This will launch a local Gradio web interface where you can test the model with custom inputs."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2477,
     "sourceId": 4140,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11420.189149,
   "end_time": "2025-11-25T14:05:14.129448",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-25T10:54:53.940299",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
